---
title: "p8105_hw5_tc3326"
author: "KK Chen"
date: "2024-11-15"
output: github_document
---

```{r setup, include = FALSE, message = FALSE}
library(tidyverse)
library(ggplot2)
```

# Problem 2
### Set Parameters and Simulate Data
```{r}
simulate_t_test = function(true_mean, sample_size = 30, std_dev = 5) 
  {
  simulated_data = tibble(sample_values = rnorm(sample_size, true_mean, std_dev))
  t_test_result = t.test(simulated_data$sample_values, mu = 0)
  cleaned_result = broom::tidy(t_test_result)
  
  result = tibble(
    sample_mean = cleaned_result$estimate,
    p_value = cleaned_result$p.value,
  )
  
  return(result)
  }
```

```{r}
simulation_results_mu_0 = 
  tibble(iter = 1:5000) %>%
  mutate(simulation_output = map(iter, ~simulate_t_test(true_mean = 0))) %>%
  unnest(simulation_output)

simulation_results_mu_0
```

```{r}
true_mean_values = c(1, 2, 3, 4, 5, 6)

sim_res_multiple_means = 
  expand_grid(
    true_mean = true_mean_values,
    iter = 1:5000 ) %>%
  mutate(simulation_output = map(true_mean, ~simulate_t_test(true_mean = .x))) %>%
  unnest(simulation_output, names_sep = "_")

sim_res_multiple_means
```

### Plot: Power of Test vs. True Mean
```{r}
power_plot <- sim_res_multiple_means %>%
  group_by(true_mean) %>%
  summarize(power = mean(simulation_output_p_value < 0.05)) %>%
  ggplot(aes(x = true_mean, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power vs. True Mean",
    x = "True Mean (¬µ)",
    y = "Power (Proportion of Null Rejected)"
  ) +
  theme_minimal()

power_plot
```

*As the effect size increases, the power of the test also increases. As the effect size grows (the difference between the true mean and the null hypothesis mean of 0 becomes larger), the test becomes more likely to reject the null hypothesis, resulting in higher power. Also, there is non-linear growth. The power rises substantially from Œº=1 to Œº=3. However, as Œº approaches 5 and 6, the power begins to plateau near 1. This suggests that once the effect size is large enough, almost all tests reject the null hypothesis, reaching close to 100% power. 

###  Plot: Average estimate of ùúáÃÇ vs True value ofŒº
```{r}
mean_estimates_plot <- sim_res_multiple_means %>%
  group_by(true_mean) %>%
  summarize(
    avg_sample_mean = mean(simulation_output_sample_mean),
    avg_sample_mean_rejected = mean(simulation_output_sample_mean[simulation_output_p_value < 0.05])
  ) %>%
  ggplot(aes(x = true_mean)) +
  geom_line(aes(y = avg_sample_mean, color = "Average ŒºÃÇ")) +
  geom_line(aes(y = avg_sample_mean_rejected, color = "Average ŒºÃÇ Rejected Null")) +
  labs(
    title = "Average Estimate of ŒºÃÇ vs True Value of Œº",
    x = " True Value of (¬µ)",
    y = "Average Estimate of ŒºÃÇ",
    color = "Estimate Type"
  ) +
  theme_minimal()

mean_estimates_plot
```

* Yes, the sample average of ŒºÃÇ across tests where the null was rejected is approximately equal to the true value of Œº, particularly for higher values of 
Œº. This alignment occurs because larger effect sizes reduce selection bias. Larger effect sizes make it easier to detect a true difference from zero, resulting in a higher proportion of samples where the null hypothesis is rejected (improve power of test).

# Problem 3
### Describe the raw data
```{r}
homicides = read_csv("./data/homicide-data.csv")
print(homicides)
```

* The dataset contains 52,179 rows and 12 columns. It provides detailed information about homicide cases in 50 large U.S. cities. Below is a description of each column:\
1. uid: A unique identifier for each homicide case, formatted with a city code prefix. \
2. reported_date: The date the homicide was reported, recorded as an 8-digit numeric value in the format YYYYMMDD \
3. victim_last and victim_first: The last and first names of the victim.\
4. victim_race: The racial or ethnic background of the victim.\
5. victim_age: The age of the victim at the time of death.\
6. victim_sex: The gender of the victim.\
5. city and state: The city and state where the homicide occurred.\
6. lat and lon: The geographic coordinates (latitude and longitude) of the location where the homicide occurred.\
7. disposition: The outcome status of the case (Closed by arrest or Closed without arrest or Open/No arrest).\

### Create a city_state variable and Summarzie
```{r}
homicides <- homicides %>%
  mutate(city_state = paste(city, state, sep = ", "))

unsolved_dispositions <- c("Closed without arrest", "Open/No arrest")

homicide_summary <- homicides %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% unsolved_dispositions)
  ) %>%
  ungroup()

print(homicide_summary)
```













